{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg5FmfTWvKPz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB00Ekuqvhl4",
        "outputId": "0b5f2b9d-ee72-40ac-9456-e45006d1b16d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.21.0 dill-0.3.8 evaluate-0.4.2 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n",
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate --upgrade\n",
        "!python -m spacy download de_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-pEa4MQvrQz"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import datasets\n",
        "import tqdm\n",
        "import torchtext\n",
        "import evaluate\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pufoRGciv0hB"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDex9niWz5Hx",
        "outputId": "9aa39c74-17d8-4067-84d4-ceaa663d70d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/datasets/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "from torchtext.datasets import Multi30k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZSHqLvV0B1U",
        "outputId": "c7f99e51-afa4-484c-9589-5883cc3a6be4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchdata\n",
            "  Downloading torchdata-0.8.0-cp310-cp310-manylinux1_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.32.3)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata) (1.3.0)\n",
            "Downloading torchdata-0.8.0-cp310-cp310-manylinux1_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchdata\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 torchdata-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyq4xPat0juf",
        "outputId": "c9afc37e-601d-44fb-8fb0-c4e58132e8e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install 'portalocker>=2.0.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GkxQjaV1FPf"
      },
      "outputs": [],
      "source": [
        "import portalocker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVapVH5XHi-k",
        "outputId": "5e70e986-aca3-42a5-fb8f-d9285c7c6be1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchdata/datapipes/__init__.py:18: UserWarning: \n",
            "################################################################################\n",
            "WARNING!\n",
            "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
            "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
            "to learn more and leave feedback.\n",
            "################################################################################\n",
            "\n",
            "  deprecation_warning()\n"
          ]
        }
      ],
      "source": [
        "train_iter, valid_iter, test_iter = Multi30k(\n",
        "    root='.data', split=('train', 'valid', 'test'), language_pair=('de', 'en')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3VlWLJFH-fS",
        "outputId": "de5ec0e0-7e67-43bc-d9d0-d5342f2c8ff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche. Two young, White males are outside near many bushes.\n"
          ]
        }
      ],
      "source": [
        "src_sentence, tgt_sentence = next(iter(train_iter))\n",
        "print(src_sentence,tgt_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcXcLpTnMegA"
      },
      "outputs": [],
      "source": [
        "de_nlp = spacy.load('de_core_news_sm')\n",
        "en_nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEPuo5mTMlrO"
      },
      "outputs": [],
      "source": [
        "def tokenize_data(en_nlp, de_nlp, max_length, lower, sos_token, eos_token, data) -> dict:\n",
        "  en_text, de_text = data  # Unpack the tuple\n",
        "  en_tokens = [token.text for token in en_nlp.tokenizer(en_text)][:max_length]\n",
        "  de_tokens = [token.text for token in de_nlp.tokenizer(de_text)][:max_length]\n",
        "\n",
        "  if lower:\n",
        "    en_tokens = [i.lower() for i in en_tokens]\n",
        "    de_tokens = [i.lower() for i in de_tokens]\n",
        "\n",
        "  en_tokens = [sos_token] + en_tokens + [eos_token]\n",
        "  de_tokens = [sos_token] + de_tokens + [eos_token]\n",
        "\n",
        "  return {'en_tokens':en_tokens, 'de_tokens':de_tokens}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHVI_9ToPzIc"
      },
      "outputs": [],
      "source": [
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWrNZYM1M5Sl"
      },
      "outputs": [],
      "source": [
        "max_length = 512\n",
        "lower = True\n",
        "eos_token = '<EOS>'\n",
        "sos_token = '<SOS>'\n",
        "\n",
        "fn_kwargs = {\n",
        "    'en_nlp': en_nlp,\n",
        "    'de_nlp': de_nlp,\n",
        "    'max_length': max_length,\n",
        "    'lower': lower,\n",
        "    'sos_token': sos_token,\n",
        "    'eos_token': eos_token\n",
        "}\n",
        "\n",
        "train_data = train_iter.map(partial(tokenize_data, en_nlp, de_nlp, max_length, lower, sos_token, eos_token))\n",
        "test_data = test_iter.map(partial(tokenize_data, en_nlp, de_nlp, max_length, lower, sos_token, eos_token))\n",
        "valid_data = valid_iter.map(partial(tokenize_data, en_nlp, de_nlp, max_length, lower, sos_token, eos_token))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lqXXlmCQiV4",
        "outputId": "08ff3dcf-66fd-4c15-ef09-7e7041ab919f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4LDy_CKQtFQ",
        "outputId": "5e5d9012-d2fd-4b0d-de1e-41391b1cb169"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.utils.data.datapipes.iter.callable.MapperIterDataPipe'>\n"
          ]
        }
      ],
      "source": [
        "print(type(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7YSxJXGSzbV",
        "outputId": "546c4d48-0b29-4aa6-ba18-72b2cb9e922a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/iter/combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        }
      ],
      "source": [
        "def yield_tokens(data_iter):\n",
        "    for item in data_iter:\n",
        "        yield item['de_tokens']  # Adjust this key based on the structure of your data\n",
        "\n",
        "de_vocab = build_vocab_from_iterator(yield_tokens(train_data), min_freq=1)\n",
        "de_vocab.insert_token('<unk>', 0)  # Add <unk> token at index 0\n",
        "de_vocab.set_default_index(0)  # Set default index to 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxTbp41dTP7j"
      },
      "outputs": [],
      "source": [
        "def yield_tokens_en(data_iter):\n",
        "    for item in data_iter:\n",
        "        yield item['en_tokens']  # Adjust this key based on the structure of your data\n",
        "\n",
        "en_vocab = build_vocab_from_iterator(yield_tokens_en(train_data), min_freq=1)\n",
        "en_vocab.insert_token('<unk>', 0)  # Add <unk> token at index 0\n",
        "en_vocab.set_default_index(0)  # Set default index to 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS9cN8X7kgzC",
        "outputId": "f4714dd8-6f1e-4ddb-de4f-51e080e9c630"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'’em': 17978,\n",
              " 'ürde': 17977,\n",
              " 'üppiges': 17976,\n",
              " 'übungsstunde': 17974,\n",
              " 'übungsmatte': 17972,\n",
              " 'übungsgrün': 17971,\n",
              " 'übrigen': 17970,\n",
              " 'überzeugen': 17968,\n",
              " 'überwältigt': 17967,\n",
              " 'überwiegende': 17963,\n",
              " 'übertriebene': 17961,\n",
              " 'überstehendes': 17960,\n",
              " 'überspringt': 17959,\n",
              " 'überschwemmung': 17958,\n",
              " 'überschwemmte': 17957,\n",
              " 'überschlags': 17956,\n",
              " 'überschlagenen': 17955,\n",
              " 'überschaubaren': 17954,\n",
              " 'überschatteten': 17953,\n",
              " 'überraschten': 17952,\n",
              " 'überrascht': 17951,\n",
              " 'übermalt': 17948,\n",
              " 'übermalen': 17947,\n",
              " 'überlegen': 17945,\n",
              " 'überholt': 17943,\n",
              " 'übergießt': 17939,\n",
              " 'übergeschlagenen': 17938,\n",
              " 'überfülltes': 17935,\n",
              " 'überfüllter': 17934,\n",
              " 'überfüllte': 17933,\n",
              " 'übereinstimmenden': 17931,\n",
              " 'überdimensioniertem': 17929,\n",
              " 'überdachungen': 17927,\n",
              " 'östlichen': 17922,\n",
              " 'ölverseuchung': 17918,\n",
              " 'ölpumpe': 17916,\n",
              " 'ölkanne': 17915,\n",
              " 'öffentlich': 17913,\n",
              " 'äußerste': 17910,\n",
              " 'äteres': 17907,\n",
              " 'ärzten': 17904,\n",
              " 'ärmell': 17902,\n",
              " 'ändern': 17899,\n",
              " 'ältliche': 17898,\n",
              " 'älterem': 17896,\n",
              " 'ägyptisches': 17894,\n",
              " 'ägyptischem': 17893,\n",
              " 'zögerndes': 17890,\n",
              " 'zwischenfall': 17884,\n",
              " 'zwinkert': 17883,\n",
              " 'zwingt': 17882,\n",
              " 'zweijähriges': 17875,\n",
              " 'zweigbündel': 17873,\n",
              " 'zweifarbigen': 17872,\n",
              " 'zwei-': 17871,\n",
              " 'zuzuschauen': 17865,\n",
              " 'zuwendung': 17862,\n",
              " 'zuvor': 17860,\n",
              " 'zustimmung': 17859,\n",
              " 'zuspringt': 17857,\n",
              " 'zuschneidet': 17854,\n",
              " 'zuschauerzahl': 17853,\n",
              " 'zuschauers': 17851,\n",
              " 'zuschauern-': 17849,\n",
              " 'zuschauermengen': 17848,\n",
              " 'zuschauende': 17846,\n",
              " 'zusammenzusetzen': 17844,\n",
              " 'zusammenstehende': 17838,\n",
              " 'zusammenpassender': 17834,\n",
              " 'zusammenkehrt': 17833,\n",
              " 'zusammengerollt': 17826,\n",
              " 'zusammengepressten': 17825,\n",
              " 'zusammengekuschelt': 17823,\n",
              " 'zusammengehalten': 17822,\n",
              " 'zusammengefügt': 17821,\n",
              " 'zusammengefallen': 17820,\n",
              " 'zusammengebastelte': 17819,\n",
              " 'zusammendrückt': 17818,\n",
              " 'zurückkommt': 17811,\n",
              " 'zungenpiercing': 17803,\n",
              " 'zungen': 17802,\n",
              " 'zulässt': 17800,\n",
              " 'zuletzt': 17798,\n",
              " 'zukneift': 17795,\n",
              " 'zujubeln': 17794,\n",
              " 'zuhörerraum': 17792,\n",
              " 'zugvorrichtung': 17789,\n",
              " 'zugkarren': 17787,\n",
              " 'zuggleises': 17786,\n",
              " 'zugeknöpften': 17776,\n",
              " 'zugeknöpft': 17775,\n",
              " 'zugeguckt': 17774,\n",
              " 'zugedeckter': 17772,\n",
              " 'zufällig': 17770,\n",
              " 'zufriedenem': 17769,\n",
              " 'zufrieden': 17768,\n",
              " 'zueinanderpassenden': 17766,\n",
              " 'zuckerrohrstock': 17763,\n",
              " 'zuckerrohr': 17762,\n",
              " 'zivilpersonen': 17753,\n",
              " 'zivilisten': 17752,\n",
              " 'zimmermädchen': 17745,\n",
              " 'zigarren': 17738,\n",
              " 'ziellos': 17732,\n",
              " 'ziele': 17730,\n",
              " 'ziegenbaby': 17727,\n",
              " 'ziegelsteinweg': 17726,\n",
              " 'ziegelpflaster': 17723,\n",
              " 'ziegelboden': 17719,\n",
              " 'zeugnissen': 17717,\n",
              " 'zermahlen': 17705,\n",
              " 'zerlumpten': 17704,\n",
              " 'zerklüftete': 17701,\n",
              " 'zerkleinerten': 17700,\n",
              " 'zementtreppe': 17694,\n",
              " 'zementhügel': 17691,\n",
              " 'zeltplatzes': 17686,\n",
              " 'zeltlagers': 17685,\n",
              " 'zeltes': 17684,\n",
              " 'zeltdach': 17683,\n",
              " 'zeltbereich': 17682,\n",
              " 'zeltartigen': 17681,\n",
              " 'zeitungslesende': 17675,\n",
              " 'zeitungsjungen': 17674,\n",
              " 'zeitungsgeschäft': 17673,\n",
              " 'zeitpunkt': 17668,\n",
              " 'zeitgenössischem': 17665,\n",
              " 'zeige': 17662,\n",
              " 'zehnnägeln': 17661,\n",
              " 'zehennägel': 17660,\n",
              " 'zehennagel': 17659,\n",
              " 'zechende': 17657,\n",
              " 'zebrastreifenmantel': 17655,\n",
              " 'zebraballon': 17653,\n",
              " 'zaunpfosten': 17652,\n",
              " 'zaumzeug': 17650,\n",
              " 'zauberstäben': 17648,\n",
              " 'zartorangen': 17646,\n",
              " 'zapfventil': 17645,\n",
              " 'zanken': 17644,\n",
              " 'zales': 17643,\n",
              " 'zahnärztin': 17642,\n",
              " 'zahnuntersuchung': 17641,\n",
              " 'zahnproblemen': 17638,\n",
              " 'zahnlücken': 17637,\n",
              " 'youngster': 17632,\n",
              " 'yorkie': 17629,\n",
              " 'yorker': 17628,\n",
              " 'yo': 17625,\n",
              " 'yards': 17624,\n",
              " 'yachthafen': 17622,\n",
              " 'wüstenähnlichen': 17619,\n",
              " 'wüstensand': 17617,\n",
              " 'würzigen': 17612,\n",
              " 'wühlen': 17609,\n",
              " 'wörterbuch': 17608,\n",
              " 'wäschesack': 17605,\n",
              " 'wälzten': 17601,\n",
              " 'währende': 17598,\n",
              " 'währenddessen': 17597,\n",
              " 'wähernd': 17596,\n",
              " 'wurfgerät': 17590,\n",
              " 'wundervollen': 17587,\n",
              " 'wundervolle': 17586,\n",
              " 'wundert': 17585,\n",
              " 'wortlaut': 17579,\n",
              " 'wood': 17576,\n",
              " 'wollröcken': 17574,\n",
              " 'wolkenbedeckten': 17567,\n",
              " 'wohnwagenplatz': 17565,\n",
              " 'wohnungsküche': 17564,\n",
              " 'wohnungen': 17562,\n",
              " 'wohnhäuser': 17560,\n",
              " 'wohnhauskomplexes': 17559,\n",
              " 'wohnhaus': 17558,\n",
              " 'witz': 17555,\n",
              " 'wurfspiel': 17592,\n",
              " 'with': 17554,\n",
              " 'wissenschaftlich': 17550,\n",
              " 'wisconsin': 17548,\n",
              " 'wischmobs': 17547,\n",
              " 'wischmob': 17546,\n",
              " 'wischlappen': 17545,\n",
              " 'wirkungsvollsten': 17543,\n",
              " 'wirbeldesign': 17537,\n",
              " 'wippen': 17536,\n",
              " 'wintermützen': 17531,\n",
              " 'wintermütze': 17530,\n",
              " 'winterlandschaft': 17528,\n",
              " 'winterkopfbedeckung': 17527,\n",
              " 'winterjahreszeit': 17526,\n",
              " 'wintergarderobe': 17524,\n",
              " 'winterausrüstung': 17523,\n",
              " 'winkligen': 17522,\n",
              " 'winkende': 17521,\n",
              " 'windsurfen': 17516,\n",
              " 'windschutzscheibe': 17515,\n",
              " 'windet': 17510,\n",
              " 'winderkleidung': 17509,\n",
              " 'windeln': 17507,\n",
              " 'windeleimer': 17506,\n",
              " 'wimpern': 17503,\n",
              " 'willkommen': 17501,\n",
              " 'williams': 17500,\n",
              " 'wildwasserfluss': 17499,\n",
              " 'wildtier': 17497,\n",
              " 'wildpferd': 17496,\n",
              " 'wikingerhelm': 17491,\n",
              " 'wikinger': 17490,\n",
              " 'wiggles': 17489,\n",
              " 'wiedergibt': 17485,\n",
              " 'wickelt': 17477,\n",
              " 'wickeln': 17476,\n",
              " 'wichtiger': 17475,\n",
              " 'whole': 17474,\n",
              " 'wheels': 17469,\n",
              " 'whatever': 17468,\n",
              " 'wettstreiter': 17466,\n",
              " 'wettläufern': 17463,\n",
              " 'wettläufer': 17462,\n",
              " 'wettkämpfer': 17461,\n",
              " 'wettkampfvorbereitungen': 17460,\n",
              " 'wettkampfs': 17459,\n",
              " 'wohnungsfenster': 17563,\n",
              " 'wettkampfnummer': 17458,\n",
              " 'wettessen': 17456,\n",
              " 'wettergegerbter': 17455,\n",
              " 'wettbewerbsteilnehmer': 17452,\n",
              " 'wert': 17446,\n",
              " 'werkunterricht': 17444,\n",
              " 'werft': 17440,\n",
              " 'werbungsstand': 17438,\n",
              " 'werbespot': 17436,\n",
              " 'werbeschild': 17435,\n",
              " \"wendy's\": 17431,\n",
              " 'weltrekord': 17427,\n",
              " 'wellenreiten': 17425,\n",
              " 'welcher': 17422,\n",
              " 'welchen': 17421,\n",
              " 'weißwein': 17420,\n",
              " 'weißschattierungen': 17417,\n",
              " 'weißgekleideter': 17414,\n",
              " 'weitwinkelbild': 17413,\n",
              " 'weitsprungwettbewerb': 17412,\n",
              " 'weitsprung': 17411,\n",
              " 'weitläufiges': 17410,\n",
              " 'weitgehend': 17408,\n",
              " 'weiterhin': 17407,\n",
              " 'weitergehen': 17405,\n",
              " 'weisungen': 17404,\n",
              " 'weintrinken': 17402,\n",
              " 'zuzuspielen': 17866,\n",
              " 'weinroter': 17401,\n",
              " 'weinrot': 17400,\n",
              " 'weinflaschen': 17397,\n",
              " 'weinberg': 17393,\n",
              " 'weihnachtspapier': 17389,\n",
              " 'weihnachtsmannkostümen': 17386,\n",
              " 'weihnachtslied': 17385,\n",
              " 'weihnachtsgeschenken': 17383,\n",
              " 'weihnachtsessen': 17380,\n",
              " 'weihnachtsbäumen': 17379,\n",
              " 'weihnachtsbaums': 17378,\n",
              " 'weiher': 17377,\n",
              " 'wehenden': 17371,\n",
              " 'wehen': 17369,\n",
              " 'wegzunehmen': 17366,\n",
              " 'wegweiser': 17365,\n",
              " 'wegs': 17363,\n",
              " 'weggespült': 17359,\n",
              " 'wee': 17355,\n",
              " 'wechselt': 17353,\n",
              " 'webseite': 17351,\n",
              " 'webcam': 17349,\n",
              " 'waveboard': 17348,\n",
              " 'watscheln': 17345,\n",
              " 'wathose': 17344,\n",
              " 'wasserturm': 17339,\n",
              " 'wassertrinkend': 17337,\n",
              " 'wassersprenkler': 17333,\n",
              " 'wasserschüssel': 17329,\n",
              " 'wasserrutschen': 17328,\n",
              " 'wasserkrügen': 17321,\n",
              " 'weihnachtsfeier': 17381,\n",
              " 'wasserkrug': 17320,\n",
              " 'wassergraben': 17317,\n",
              " 'wassergefährt': 17315,\n",
              " 'wasserfällen': 17314,\n",
              " 'wasserfallkulisse': 17312,\n",
              " 'wohlverdienten': 17556,\n",
              " 'wasserfahrrad': 17311,\n",
              " 'wasserdichten': 17308,\n",
              " 'wasserbüffel': 17307,\n",
              " 'wasserblauen': 17306,\n",
              " 'wasserbeckens': 17304,\n",
              " 'wasserballspiel': 17303,\n",
              " 'waschseife': 17297,\n",
              " 'waschraum': 17296,\n",
              " 'zahllose': 17635,\n",
              " 'waschanlage': 17291,\n",
              " 'warnzeichen': 17283,\n",
              " 'warnt': 17282,\n",
              " 'warnschild': 17281,\n",
              " 'warmhalteplatte': 17280,\n",
              " 'wappen': 17276,\n",
              " 'wandmalereien': 17272,\n",
              " 'wanderstiefeln': 17270,\n",
              " 'wanderschuhen': 17269,\n",
              " 'wanderschuhe': 17268,\n",
              " 'wanderhemd': 17265,\n",
              " 'wandbildes': 17263,\n",
              " 'wandbehang': 17261,\n",
              " 'walzers': 17260,\n",
              " 'walt': 17258,\n",
              " 'walmarts': 17257,\n",
              " 'waldland': 17247,\n",
              " 'wal': 17243,\n",
              " 'wakeboarded': 17240,\n",
              " 'wahrzeichens': 17238,\n",
              " 'wahllokal': 17232,\n",
              " 'wahlkampfschild': 17231,\n",
              " 'wagenrädern': 17229,\n",
              " 'wagenladung': 17228,\n",
              " 'wagemutiger': 17227,\n",
              " 'waffengestellen': 17225,\n",
              " 'waffeln': 17223,\n",
              " 'wackelt': 17221,\n",
              " 'wackelig': 17219,\n",
              " 'wacht': 17218,\n",
              " 'wachsmalstiften': 17217,\n",
              " 'waagen': 17212,\n",
              " 'völkermord': 17211,\n",
              " 'vätern': 17208,\n",
              " 'vuitton': 17206,\n",
              " 'vorübereilen': 17202,\n",
              " 'vorzeigt': 17200,\n",
              " 'vorwärtssalto': 17199,\n",
              " 'vorwärtsbewegt': 17198,\n",
              " 'vorstehhunde': 17193,\n",
              " 'vorstadtstraße': 17192,\n",
              " 'vorstadt': 17191,\n",
              " 'vorspiel': 17190,\n",
              " 'vorspeisen': 17189,\n",
              " 'vorsingt': 17187,\n",
              " 'vorschulfahrrad': 17184,\n",
              " 'zwillingswagen': 17881,\n",
              " 'vors': 17183,\n",
              " 'vorrichtungen': 17182,\n",
              " 'vornübergebeugter': 17180,\n",
              " 'vormittag': 17179,\n",
              " 'vorliegende': 17178,\n",
              " 'vorlauf': 17176,\n",
              " 'yos': 17631,\n",
              " 'vorhängen': 17175,\n",
              " 'vorgesetzter': 17169,\n",
              " 'vorderes': 17161,\n",
              " 'vorbeizudribbeln': 17156,\n",
              " 'vorbeischwimmt': 17153,\n",
              " 'vorbeikommende': 17149,\n",
              " 'vorbeigehende': 17148,\n",
              " 'vorbeigefahren': 17147,\n",
              " 'vorbeifließen': 17146,\n",
              " 'vorbeifliegen': 17144,\n",
              " 'volvo': 17141,\n",
              " 'vollzugsbeamter': 17139,\n",
              " 'vollständiger': 17138,\n",
              " 'vollgestopft': 17135,\n",
              " 'vollgepackten': 17134,\n",
              " 'volleyballteam': 17132,\n",
              " 'volleyballspielers': 17131,\n",
              " 'volley': 17126,\n",
              " 'vollbringt': 17124,\n",
              " 'vollbart': 17123,\n",
              " 'volkshochschule': 17121,\n",
              " 'vokabeln': 17120,\n",
              " 'vogelkäfig': 17117,\n",
              " 'vogelhäuschen': 17116,\n",
              " 'violinsolisten': 17112,\n",
              " 'vikings': 17109,\n",
              " 'vietnamesische': 17107,\n",
              " 'vietnamese': 17106,\n",
              " 'vorwiegend': 17197,\n",
              " 'vierzehn': 17105,\n",
              " 'vierstöckigen': 17102,\n",
              " 'vierbeiniges': 17096,\n",
              " 'zwar': 17870,\n",
              " 'vierbeinigen': 17095,\n",
              " 'vierbeinige': 17094,\n",
              " 'vielfältigen': 17093,\n",
              " 'vielbesuchten': 17091,\n",
              " 'vielbefahrene': 17090,\n",
              " 'viehauktion': 17087,\n",
              " 'videospielhalle': 17086,\n",
              " 'videospielen': 17084,\n",
              " 'videomonitor': 17082,\n",
              " 'videomacher': 17081,\n",
              " 'veteranenaufmarsch': 17077,\n",
              " 'vesperbrot': 17076,\n",
              " 'vespa': 17075,\n",
              " 'vierter': 17104,\n",
              " 'verziertes': 17070,\n",
              " 'verwüstetes': 17064,\n",
              " 'zeitungsbehälter': 17672,\n",
              " 'verwöhnt': 17063,\n",
              " 'verwundeter': 17062,\n",
              " 'verwundert': 17061,\n",
              " 'verwickelten': 17056,\n",
              " 'verwelktem': 17055,\n",
              " 'verwahrloster': 17053,\n",
              " 'verwahrloste': 17051,\n",
              " 'vertreten': 17046,\n",
              " 'vertrauliches': 17045,\n",
              " 'vertikale': 17043,\n",
              " 'versunken': 17038,\n",
              " 'verstopfen': 17036,\n",
              " 'verspielt': 17030,\n",
              " 'versperrt': 17028,\n",
              " 'verspeist': 17027,\n",
              " 'versorgungsbetriebe': 17026,\n",
              " 'versehener': 17023,\n",
              " 'verschüttet': 17022,\n",
              " 'verschwitzter': 17020,\n",
              " 'verschwitzte': 17019,\n",
              " 'verschwimmen': 17017,\n",
              " 'verschriebene': 17016,\n",
              " 'verschnörkelten': 17015,\n",
              " 'verschmutzter': 17014,\n",
              " 'verschmierten': 17011,\n",
              " 'zeitungsverkäufer': 17679,\n",
              " 'verschmiert': 17010,\n",
              " 'verschlungene': 17009,\n",
              " 'verschlossenen': 17008,\n",
              " 'verschiedenartigen': 17002,\n",
              " 'verrenkt': 16996,\n",
              " 'verprügelt': 16992,\n",
              " 'verpacken': 16988,\n",
              " 'verschiedenster': 17004,\n",
              " 'verneigen': 16987,\n",
              " 'verlängert': 16981,\n",
              " 'verlorenen': 16980,\n",
              " 'verlieren': 16977,\n",
              " 'verliebte': 16975,\n",
              " 'verliebt': 16974,\n",
              " 'verlaufenden': 16972,\n",
              " 'verknotetes': 16964,\n",
              " 'verkleidungen': 16963,\n",
              " 'verkehrsmitteln': 16957,\n",
              " 'verkehrskegel': 16955,\n",
              " 'verkehrshelfer': 16954,\n",
              " 'ärztliche': 17905,\n",
              " 'verkehrsampeln': 16952,\n",
              " 'verkaufsständen': 16948,\n",
              " 'verkaufsstands': 16947,\n",
              " 'verkaufende': 16944,\n",
              " 'verizon': 16943,\n",
              " 'verhärmt': 16942,\n",
              " 'verheddern': 16940,\n",
              " 'verharren': 16939,\n",
              " 'verhaften': 16937,\n",
              " 'verfügbaren': 16927,\n",
              " 'verfugt': 16925,\n",
              " 'wälzenden': 17600,\n",
              " 'verfehlten': 16924,\n",
              " 'verfangen': 16923,\n",
              " 'verdächtigen': 16919,\n",
              " 'verdreckter': 16916,\n",
              " 'verdreckte': 16914,\n",
              " 'verdient': 16912,\n",
              " 'verbrechens': 16909,\n",
              " 'verboten“-schilds': 16908,\n",
              " 'verborgene': 16906,\n",
              " 'verbindungselemente': 16905,\n",
              " 'verbeugung': 16903,\n",
              " 'weinland': 17399,\n",
              " 'verbeißt': 16900,\n",
              " 'veranstalten': 16896,\n",
              " 'verandastufen': 16894,\n",
              " 'wildem': 17492,\n",
              " 'verabreicht': 16892,\n",
              " 'venusmuscheln': 16890,\n",
              " 'ventilator': 16888,\n",
              " 'vegetationsfeld': 16887,\n",
              " 'vegetation': 16886,\n",
              " 'vatikan': 16885,\n",
              " 'variante': 16883,\n",
              " 'vampirkostüme': 16882,\n",
              " 'überdimensionierte': 17928,\n",
              " 'uw': 16881,\n",
              " 'utep': 16880,\n",
              " 'utensilien': 16879,\n",
              " 'urwald': 16878,\n",
              " 'urne': 16877,\n",
              " 'ureinwohnertracht': 16869,\n",
              " 'urdu': 16866,\n",
              " 'unverwandt': 16863,\n",
              " 'untätig': 16862,\n",
              " 'unterzeichnen': 16859,\n",
              " 'unterwasserfoto': 16858,\n",
              " 'untertage': 16855,\n",
              " 'unterstützungstruppe': 16854,\n",
              " 'unterstützt': 16853,\n",
              " 'unterschlupf': 16850,\n",
              " 'unterschiedlichem': 16848,\n",
              " 'unterschiede': 16846,\n",
              " 'unternehmens': 16841,\n",
              " 'unterirdische': 16836,\n",
              " 'unterhose': 16835,\n",
              " 'unterhemden': 16834,\n",
              " 'unterhemdchen': 16833,\n",
              " 'unterhaltsam': 16832,\n",
              " 'unterhaltender': 16831,\n",
              " 'untergehakt': 16825,\n",
              " 'untere': 16823,\n",
              " 'unterdessen': 16822,\n",
              " 'unterbrochen': 16821,\n",
              " 'unterarme': 16819,\n",
              " 'unsinn': 16817,\n",
              " 'unschuldiges': 16813,\n",
              " 'unscharfes': 16811,\n",
              " 'unordentlich': 16808,\n",
              " 'unkonventionellen': 16805,\n",
              " 'universitätsmannschaften': 16802,\n",
              " 'universelle': 16801,\n",
              " 'wasserspritzen': 17334,\n",
              " 'unglücklicher': 16799,\n",
              " 'vorlesungssaal': 17177,\n",
              " 'unglaublichen': 16796,\n",
              " 'ungewohnten': 16793,\n",
              " 'ungestümen': 16792,\n",
              " 'weitergeht': 17406,\n",
              " 'ungepflegter': 16790,\n",
              " 'ungepflegtem': 16789,\n",
              " 'ungepflasterten': 16788,\n",
              " 'ungekämmten': 16786,\n",
              " 'une': 16781,\n",
              " 'unbekannt': 16778,\n",
              " 'unbehaglich': 16777,\n",
              " 'umzäunte': 16771,\n",
              " 'umweltverschmutzung': 16768,\n",
              " 'umstellen': 16767,\n",
              " 'umschalten': 16762,\n",
              " 'ums': 16761,\n",
              " 'wettrennens': 17464,\n",
              " 'umrunden': 16760,\n",
              " 'umringen': 16757,\n",
              " 'umrandeten': 16756,\n",
              " 'wickeltuch': 17479,\n",
              " 'umläuft': 16753,\n",
              " 'umlaufen': 16752,\n",
              " 'umkurvt': 16751,\n",
              " 'umkleidezelt': 16750,\n",
              " 'umhergehen': 16743,\n",
              " 'umgeweht': 16740,\n",
              " 'umgestalten': 16739,\n",
              " 'älteste': 17897,\n",
              " 'umgelegt': 16738,\n",
              " 'umgehängt': 16736,\n",
              " 'umgehen': 16734,\n",
              " 'umgefüllt': 16733,\n",
              " 'umgebenes': 16732,\n",
              " 'umgang': 16731,\n",
              " 'umfallen': 16728,\n",
              " 'umarmende': 16726,\n",
              " 'ugg': 16722,\n",
              " 'uferpromenade': 16716,\n",
              " 'uferlinie': 16715,\n",
              " 'udn': 16712,\n",
              " 'u.s.': 16710,\n",
              " 'türmt': 16708,\n",
              " 'töpfern': 16701,\n",
              " 'töchtern': 16700,\n",
              " 'täter': 16697,\n",
              " 'täschchen': 16696,\n",
              " 'tänzerpaar': 16695,\n",
              " 'typisches': 16693,\n",
              " 'tust': 16690,\n",
              " 'turnwettbewerb': 16689,\n",
              " 'turnhallenboden': 16685,\n",
              " 'weine': 17394,\n",
              " 'turngeräten': 16684,\n",
              " 'turners': 16683,\n",
              " 'turnen': 16681,\n",
              " 'turnanzüge': 16679,\n",
              " 'turnanzug': 16678,\n",
              " 'turmuhr': 16677,\n",
              " 'tunnelinneren': 16670,\n",
              " 'tuben': 16669,\n",
              " 'tubaspieler': 16668,\n",
              " 'tubas': 16667,\n",
              " 'trümmern': 16666,\n",
              " 'tröstliche': 16663,\n",
              " 'tröstet': 16662,\n",
              " 'tränen': 16661,\n",
              " 'trägertop': 16660,\n",
              " 'trägerlosen': 16658,\n",
              " 'wendung': 17430,\n",
              " 'träge': 16657,\n",
              " 'truthahnbraten': 16656,\n",
              " 'trudelt': 16652,\n",
              " 'trotten': 16650,\n",
              " 'tropenfische': 16648,\n",
              " 'trockentuch': 16641,\n",
              " 'trockenhaube': 16640,\n",
              " 'trockenanzug': 16637,\n",
              " 'triumphierend': 16636,\n",
              " 'triste': 16635,\n",
              " 'trinkend': 16628,\n",
              " 'trinkeldglas': 16627,\n",
              " 'trinkbecher': 16625,\n",
              " 'trichters': 16624,\n",
              " 'tribaltattoo': 16623,\n",
              " 'treppeneingang': 16614,\n",
              " 'trendige': 16611,\n",
              " 'treffens': 16609,\n",
              " 'trapeznummer': 16607,\n",
              " 'transvestit': 16606,\n",
              " 'transporthilfe': 16605,\n",
              " 'trainingspylone': 16596,\n",
              " 'trainingsjacke': 16594,\n",
              " 'trainingsgeräten': 16592,\n",
              " 'trainingsgerät': 16591,\n",
              " 'trainingsfortschritt': 16590,\n",
              " 'trainingseinrichtung': 16589,\n",
              " 'trainers': 16588,\n",
              " 'tragendes': 16585,\n",
              " 'tragende': 16583,\n",
              " 'tragbaren': 16582,\n",
              " 'tragbare': 16581,\n",
              " 'trabt': 16576,\n",
              " 'touristenstand': 16570,\n",
              " 'touristenbus': 16568,\n",
              " 'totenschädel': 16564,\n",
              " 'totenkopfsymbol': 16562,\n",
              " 'totenkopfbild': 16561,\n",
              " 'totempfahl': 16558,\n",
              " 'torstange': 16556,\n",
              " 'tors': 16555,\n",
              " 'weinenden': 17396,\n",
              " 'toronto': 16553,\n",
              " 'tornister': 16552,\n",
              " 'tornetzes': 16551,\n",
              " 'tormann': 16550,\n",
              " 'torlosen': 16549,\n",
              " 'toren': 16546,\n",
              " 'tore': 16545,\n",
              " 'torbereich': 16544,\n",
              " 'topfs': 16541,\n",
              " 'tonware': 16535,\n",
              " 'tonschale': 16532,\n",
              " 'tonnen': 16531,\n",
              " 'tongefäß': 16528,\n",
              " 'tomatenpastete': 16524,\n",
              " 'toben': 16519,\n",
              " 'toastbrot': 16517,\n",
              " 'tischtuch': 16514,\n",
              " 'tischsäge': 16512,\n",
              " 'tischs': 16510,\n",
              " 'tischdecken': 16507,\n",
              " 'tintenverschmierter': 16506,\n",
              " 'tiki': 16501,\n",
              " 'tigermotiv': 16498,\n",
              " 'tierpfleger': 16496,\n",
              " 'tiermotivdruck': 16494,\n",
              " 'tieres': 16489,\n",
              " 'tieren': 16488,\n",
              " 'tierballons': 16487,\n",
              " 'wortzeichen': 17580,\n",
              " 'tiefseetaucher': 16484,\n",
              " 'tiefblauem': 16481,\n",
              " 'ticket': 16479,\n",
              " 'thorn': 16476,\n",
              " 'thora': 16475,\n",
              " 'themenpark': 16474,\n",
              " 'themen': 16473,\n",
              " 'theken': 16472,\n",
              " 'theaterstudenten': 16468,\n",
              " 'textilien': 16461,\n",
              " 'teva': 16459,\n",
              " 'teufelskostüm': 16455,\n",
              " 'testparcours': 16453,\n",
              " 'terriermischling': 16451,\n",
              " 'terrible': 16450,\n",
              " 'terminals': 16449,\n",
              " 'terminal': 16448,\n",
              " 'tennisspielerinnen': 16444,\n",
              " 'tennisschlag': 16442,\n",
              " 'tennisrock': 16441,\n",
              " 'tennisnetzes': 16439,\n",
              " 'tenniskleid': 16437,\n",
              " 'tennisbälle': 16435,\n",
              " 'ten': 16432,\n",
              " 'teleskops': 16427,\n",
              " 'telefonmast': 16423,\n",
              " 'telefonierender': 16421,\n",
              " 'teilnehmergruppe': 16418,\n",
              " 'teigrolle': 16417,\n",
              " 'türschwelle': 16709,\n",
              " 'teiches': 16416,\n",
              " 'tehelka': 16415,\n",
              " 'teenagers': 16412,\n",
              " 'teeladen': 16411,\n",
              " 'teekanne': 16410,\n",
              " 'technischen': 16409,\n",
              " 'technische': 16408,\n",
              " 'technikexamen': 16407,\n",
              " 'tebow': 16404,\n",
              " 'teamtrikot': 16403,\n",
              " 'teamsportart': 16402,\n",
              " 'teammitglieder': 16401,\n",
              " 'teamchef': 16397,\n",
              " 'tea': 16395,\n",
              " 'taxikostüm': 16394,\n",
              " 'taxikleinbus': 16393,\n",
              " 'ärmellose': 17903,\n",
              " 'tupfen': 16671,\n",
              " 'tausenden': 16392,\n",
              " 'tausende': 16391,\n",
              " 'tatenlos': 16384,\n",
              " 'taschentücher': 16382,\n",
              " 'tartuffe': 16379,\n",
              " 'tanzschritt': 16375,\n",
              " 'tanzprogramm': 16374,\n",
              " 'tanzoutfits': 16370,\n",
              " 'zugemüllt': 17777,\n",
              " 'würgt': 17611,\n",
              " 'tanzgruppe': 16367,\n",
              " 'wildwasserbahn': 17498,\n",
              " 'wasserloch': 17323,\n",
              " 'tanzfigur': 16366,\n",
              " 'tannenzapfen': 16357,\n",
              " 'tannehill': 16356,\n",
              " 'tanklastwagens': 16354,\n",
              " 'tamburinen': 16351,\n",
              " 'tambourin': 16349,\n",
              " 'tambor': 16348,\n",
              " 'talgegend': 16346,\n",
              " 'takes': 16344,\n",
              " 'taillenbund': 16342,\n",
              " 'tageszeitbedingt': 16341,\n",
              " 'tagesmesse': 16339,\n",
              " 'tageslichts': 16338,\n",
              " 'tageslicht': 16337,\n",
              " 'tae': 16334,\n",
              " 'tab': 16331,\n",
              " 'süße': 16330,\n",
              " 'südostasiatischen': 16327,\n",
              " 'südamerika': 16324,\n",
              " 'säuglingsjunge': 16319,\n",
              " 'säht': 16314,\n",
              " 'system': 16312,\n",
              " 'synchronschwimmern': 16309,\n",
              " 'synchronschwimmen': 16308,\n",
              " 'synchronisierten': 16307,\n",
              " 'swat': 16301,\n",
              " 'sva': 16299,\n",
              " 'surfoberteil': 16298,\n",
              " 'surferin': 16296,\n",
              " 'surferhemd': 16295,\n",
              " 'surfboarder': 16292,\n",
              " 'suppenschale': 16290,\n",
              " 'supermarktgang': 16288,\n",
              " 'supermann': 16287,\n",
              " 'superheldenkostümen': 16286,\n",
              " 'sun': 16283,\n",
              " 'sugarland': 16280,\n",
              " 'sucher': 16279,\n",
              " 'subs': 16278,\n",
              " 'subjekts': 16277,\n",
              " 'stützmauer': 16275,\n",
              " 'stütze': 16274,\n",
              " 'umzäuntem': 16772,\n",
              " 'stürmischen': 16271,\n",
              " 'stürmen': 16270,\n",
              " 'stöpselt': 16267,\n",
              " 'städter': 16262,\n",
              " 'styroporbechern': 16259,\n",
              " 'styroporbecher': 16258,\n",
              " 'stylus': 16257,\n",
              " 'stylt': 16256,\n",
              " 'stylistischen': 16255,\n",
              " 'stutzen': 16253,\n",
              " 'wirkender': 17541,\n",
              " 'sturmhaube': 16250,\n",
              " 'stumpf': 16247,\n",
              " 'stuhlreihe': 16243,\n",
              " 'stuhlgruppe': 16242,\n",
              " 'stuhle': 16241,\n",
              " 'studiokulisse': 16240,\n",
              " 'studierende': 16239,\n",
              " 'studentinnen': 16238,\n",
              " 'stuckgebäudes': 16234,\n",
              " 'strümpfe': 16233,\n",
              " 'strömung': 16232,\n",
              " 'strömen': 16231,\n",
              " 'struwwelfrisur': 16229,\n",
              " 'umzäunungsmauer': 16773,\n",
              " 'strumpfhalter': 16228,\n",
              " 'stromschnelle': 16226,\n",
              " 'stromkreisen': 16225,\n",
              " 'strohhüten': 16222,\n",
              " 'strohfläche': 16218,\n",
              " 'strohdach': 16217,\n",
              " 'stroboskoplichtern': 16216,\n",
              " 'stroboskoplicht': 16214,\n",
              " 'stripes': 16213,\n",
              " 'verdorrten': 16913,\n",
              " 'string': 16211,\n",
              " 'strickleiter': 16209,\n",
              " 'tretenden': 16618,\n",
              " 'strichzeichnung': 16208,\n",
              " 'strichen': 16207,\n",
              " 'streuen': 16205,\n",
              " 'streife': 16203,\n",
              " 'wissenschaftliche': 17551,\n",
              " 'streien': 16202,\n",
              " 'streichinstrumenten': 16200,\n",
              " 'streichhölzern': 16198,\n",
              " 'streichholzschachteln': 16197,\n",
              " 'streethockeyspieler': 16195,\n",
              " 'straßenzeichen': 16191,\n",
              " 'straßenwerbung': 16190,\n",
              " 'straßenverkehr': 16189,\n",
              " 'straßenverkaufsstand': 16188,\n",
              " 'straßenumzug': 16186,\n",
              " 'straßentänzer': 16185,\n",
              " 'straßentrommlern': 16184,\n",
              " 'straßenseiten': 16182,\n",
              " 'straßenreparaturen': 16178,\n",
              " 'straßenrennens': 16177,\n",
              " 'straßenplatten': 16175,\n",
              " 'straßenmusikant': 16173,\n",
              " 'zuschauerrängen': 17850,\n",
              " 'straßenläufer': 16172,\n",
              " 'straßenküchenverkäufer': 16169,\n",
              " 'straßenhandwerker': 16165,\n",
              " 'straßenbaustelle': 16163,\n",
              " 'straßenbahnwagen': 16161,\n",
              " 'straßenaufführung': 16156,\n",
              " 'straßenampel': 16153,\n",
              " 'straßenabsperrungen': 16152,\n",
              " 'strandwache': 16148,\n",
              " 'strandtasche': 16146,\n",
              " 'strandtag': 16145,\n",
              " 'strandszenerie': 16144,\n",
              " 'strandparty': 16142,\n",
              " 'strandkorb': 16141,\n",
              " 'strandhauses': 16140,\n",
              " 'strandbad': 16138,\n",
              " 'strammer': 16137,\n",
              " 'strahl': 16134,\n",
              " 'strafverfolgungsbehörde': 16133,\n",
              " 'wasserskilaufen': 17331,\n",
              " 'stoppzeichen': 16127,\n",
              " 'stonehurst': 16122,\n",
              " 'stolziert': 16121,\n",
              " 'stollenschuhen': 16119,\n",
              " 'stofftierkostüm': 16117,\n",
              " 'stoffaffe': 16111,\n",
              " 'stockcar': 16109,\n",
              " 'stockball': 16108,\n",
              " 'stochert': 16107,\n",
              " 'swan': 16300,\n",
              " 'stochern': 16106,\n",
              " 'stitch': 16105,\n",
              " 'stirnrunzelnd': 16103,\n",
              " 'stinkt': 16100,\n",
              " 'sting': 16099,\n",
              " 'stimmungsvollen': 16098,\n",
              " 'stillstand': 16096,\n",
              " 'stillgelegten': 16095,\n",
              " 'stillen': 16094,\n",
              " 'stiermaske': 16092,\n",
              " 'sterntattoo': 16077,\n",
              " 'sternhalma': 16075,\n",
              " 'sternförmigen': 16074,\n",
              " 'sternform': 16072,\n",
              " 'sterne': 16071,\n",
              " 'stepptanz': 16070,\n",
              " 'zugedecktes': 17773,\n",
              " 'steinzufahrt': 16065,\n",
              " 'steinwürfel': 16064,\n",
              " 'steinterrasse': 16061,\n",
              " 'uriniert': 16870,\n",
              " 'steinteich': 16060,\n",
              " 'steinofen': 16055,\n",
              " 'windsurft': 17517,\n",
              " 'steinlöwen': 16053,\n",
              " 'steingehweg': 16048,\n",
              " 'steingebilde': 16047,\n",
              " 'steinfläche': 16046,\n",
              " 'steinfliese': 16045,\n",
              " 'steinfiguren': 16044,\n",
              " 'steinernes': 16043,\n",
              " 'steinerne': 16042,\n",
              " 'steinbildhauer': 16036,\n",
              " 'steigenlassen': 16033,\n",
              " 'steht:“long': 16032,\n",
              " 'stehlen': 16031,\n",
              " 'stehendem': 16030,\n",
              " 'überholen': 17942,\n",
              " 'steh': 16029,\n",
              " 'wimperntusche': 17504,\n",
              " 'steck': 16028,\n",
              " 'steakhouse': 16027,\n",
              " 'staunender': 16024,\n",
              " 'staubsaugen': 16021,\n",
              " 'stattfinden': 16016,\n",
              " 'stativs': 16015,\n",
              " 'startnummer': 16011,\n",
              " 'startklappen': 16010,\n",
              " 'startblöcken': 16008,\n",
              " 'startblock': 16007,\n",
              " 'starkes': 16004,\n",
              " 'starke': 16001,\n",
              " 'stanzt': 15997,\n",
              " 'stanford': 15995,\n",
              " 'standstreifen': 15994,\n",
              " 'stands': 15993,\n",
              " 'vons': 17142,\n",
              " 'standbohrmaschine': 15990,\n",
              " 'stampfen': 15988,\n",
              " 'stammesangehöriger': 15984,\n",
              " 'vhs': 17078,\n",
              " 'stahlträgern': 15980,\n",
              " 'stahlhelm': 15977,\n",
              " 'stahlgitterabsperrung': 15976,\n",
              " 'wasservogel': 17340,\n",
              " 'staffordshire': 15972,\n",
              " 'stadtzentrum': 15969,\n",
              " 'stadtverkehr': 15968,\n",
              " 'stadtstraßen': 15965,\n",
              " 'stadtkulisse': 15961,\n",
              " 'stadtkreuzung': 15960,\n",
              " 'stadium': 15955,\n",
              " 'stadionsitzen': 15954,\n",
              " 'stacheldraht': 15951,\n",
              " 'stachelarmband': 15950,\n",
              " 'stachel': 15949,\n",
              " 'stabs': 15948,\n",
              " 'stabilisierung': 15947,\n",
              " 'stabhochspringerin': 15945,\n",
              " 'staatsangehörige': 15943,\n",
              " 'spülbecken': 15937,\n",
              " 'spätschicht': 15935,\n",
              " 'sprünge': 15928,\n",
              " 'sprühkünstlerin': 15926,\n",
              " 'sprungwettbewerb': 15921,\n",
              " 'sprudelt': 15916,\n",
              " 'sprudelnde': 15915,\n",
              " 'spruchbändern': 15914,\n",
              " 'spritzern': 15911,\n",
              " 'spritzendes': 15910,\n",
              " 'spritzenden': 15909,\n",
              " 'spritzbeutel': 15908,\n",
              " 'spritz': 15907,\n",
              " 'sprinten': 15905,\n",
              " 'sprinklerspielzeug': 15904,\n",
              " 'springsteen': 15902,\n",
              " 'springreiter': 15901,\n",
              " 'zwangsjacke': 17869,\n",
              " 'zusammenhang': 17832,\n",
              " 'tragesitz': 16586,\n",
              " 'springer': 15899,\n",
              " 'springburg': 15896,\n",
              " 'springbrett': 15892,\n",
              " 'sprich': 15891,\n",
              " 'sprenger': 15890,\n",
              " 'sprecherin': 15889,\n",
              " 'sprecher': 15888,\n",
              " 'sportzentrum': 15887,\n",
              " 'sportwägen': 15886,\n",
              " 'sportteil': 15883,\n",
              " 'sporttasche': 15880,\n",
              " 'sportruderboot': 15873,\n",
              " 'sportposter': 15870,\n",
              " 'sportoutfit': 15869,\n",
              " 'sportmotorrad': 15868,\n",
              " 'sportmotiv': 15867,\n",
              " 'sportmannschaften': 15866,\n",
              " 'sportmannschaft': 15865,\n",
              " 'sportlichen': 15864,\n",
              " 'sportlich': 15863,\n",
              " 'sportkurs': 15860,\n",
              " 'sportkinderwagen': 15859,\n",
              " 'sportgetränk': 15856,\n",
              " 'sportclub': 15855,\n",
              " 'sportbogenschütze': 15854,\n",
              " 'sportausrüstung': 15851,\n",
              " 'sportart': 15850,\n",
              " 'sportanzug': 15849,\n",
              " 'spitzhut': 15847,\n",
              " 'verkünden': 16966,\n",
              " 'spitzhacke': 15846,\n",
              " 'spitzenkragen': 15844,\n",
              " 'spitzenhut': 15843,\n",
              " 'spieß': 15838,\n",
              " 'spielzimmer': 15837,\n",
              " 'spielzeugwelpen': 15836,\n",
              " 'spielzeugvogel': 15834,\n",
              " 'spielzeugtier': 15833,\n",
              " ...}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en_vocab.get_stoi()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBJzUv9bTstr"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRnljVi-TyN0"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwJUmBxGxZO6"
      },
      "outputs": [],
      "source": [
        "def tokens_to_indices(tokens, vocab):\n",
        "    return [vocab.__getitem__(token) if isinstance(token, str) else 0 for token in tokens]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch = [torch.tensor(tokens_to_indices(item['en_tokens'], en_vocab)) for item in batch]\n",
        "    trg_batch = [torch.tensor(tokens_to_indices(item['de_tokens'], de_vocab)) for item in batch]\n",
        "\n",
        "    # Pad sequences to the maximum length in the batch\n",
        "    src_batch = pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
        "    trg_batch = pad_sequence(trg_batch, padding_value=0, batch_first=True)\n",
        "\n",
        "    return {'en_tokens': src_batch.to(device), 'de_tokens': trg_batch.to(device)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_An2sSM0Tt_d"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator = DataLoader(train_data, batch_size = BATCH_SIZE, collate_fn=collate_fn)\n",
        "valid_iterator = DataLoader(valid_data, batch_size = BATCH_SIZE, collate_fn = collate_fn)\n",
        "test_iterator = DataLoader(test_data, batch_size = BATCH_SIZE, collate_fn = collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Mq_E-rMiHjH"
      },
      "outputs": [],
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, embedding_size):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = torch.nn.Embedding(input_size, embedding_size)\n",
        "    self.dropout = torch.nn.Dropout(0.2)\n",
        "    self.rnn = torch.nn.GRU(embedding_size, self.hidden_size)\n",
        "\n",
        "  def forward(self, input):\n",
        "    #self.input = input.unsqueeze(0)\n",
        "    #print(\"C\", input.shape)\n",
        "    input = input.transpose(0, 1)\n",
        "    self.embed = self.dropout(self.embedding(input))\n",
        "    #print(\"B\", self.embed.shape)\n",
        "    output, hidden = self.rnn(self.embed)\n",
        "    #print(\"A\", output.shape, hidden.shape)\n",
        "    return hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0n4IfL6jdUx"
      },
      "outputs": [],
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "  def __init__(self, output_size, embedding_size, hidden_size):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.embedding = torch.nn.Embedding(output_size, embedding_size)\n",
        "    self.dropout = torch.nn.Dropout(0.2)\n",
        "    self.rnn = torch.nn.GRU(embedding_size+hidden_size, hidden_size)\n",
        "    self.fc = torch.nn.Linear(embedding_size+hidden_size*2, output_size)\n",
        "\n",
        "  def forward(self, input, context, hidden):\n",
        "    #print(input.shape, hidden.shape)\n",
        "    self.input = input.unsqueeze(0)\n",
        "    embed = self.dropout(self.embedding(self.input))\n",
        "    #print(\"A\", input.shape, embed.shape, context.shape)\n",
        "    self.embed = torch.concat([embed, context], dim = 2)\n",
        "    output, hidden = self.rnn(self.embed, hidden)\n",
        "    output = torch.concat((embed.squeeze(0), hidden.squeeze(0), context.squeeze(0)), dim = 1)\n",
        "    #print(\"B\", self.embed.shape, hidden.shape, context.shape)\n",
        "    #print(output.shape)\n",
        "    prediction = self.fc(output)\n",
        "    return prediction, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ekf2wiuZmSCL"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(torch.nn.Module):\n",
        "  def __init__(self, encoder, decoder, device):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "    self.batch_size = trg.shape[0]\n",
        "    #print(\"Trg\", trg.shape)\n",
        "    trg_len = trg.shape[1]\n",
        "    self.trg_vocab_size = self.decoder.output_size\n",
        "\n",
        "    outputs = torch.zeros(trg_len, self.batch_size, self.trg_vocab_size).to(self.device)\n",
        "\n",
        "    hidden = self.encoder(src)\n",
        "    context = hidden\n",
        "\n",
        "    input = trg[:, 0]\n",
        "\n",
        "    for t in range(1, trg_len):\n",
        "      output, hidden = self.decoder(input, context, hidden)\n",
        "      outputs[t] = output\n",
        "\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "      top1 = output.argmax(1)\n",
        "      #print(\"D\", top1.shape, trg[:, t].shape)\n",
        "      input = trg[:, t] if teacher_force else top1\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_x4MhnVYqSMl"
      },
      "outputs": [],
      "source": [
        "input_size = len(en_vocab)\n",
        "output_size = len(de_vocab)\n",
        "hidden_size = 512\n",
        "embedding_size = 256\n",
        "\n",
        "encoder = Encoder(input_size, hidden_size, embedding_size)\n",
        "decoder = Decoder(output_size, embedding_size, hidden_size)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWzWtZsHrCJm",
        "outputId": "ad1ef6c6-94f9-44f5-f8b1-b9ed294636c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(17980, 256)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "    (rnn): GRU(256, 512)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(10358, 256)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "    (rnn): GRU(768, 512)\n",
              "    (fc): Linear(in_features=1280, out_features=10358, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def init_weights(m):\n",
        "  for name, param in model.named_parameters():\n",
        "    torch.nn.init.normal_(param.data, mean = 0, std=0.01)\n",
        "\n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnPeVe_broUK"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "trg_idx = de_vocab.lookup_indices(['<pad>'])\n",
        "lossfn = torch.nn.CrossEntropyLoss(ignore_index = trg_idx[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xSsKkT8tFwa"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, lossfn, clip):\n",
        "  model.train()\n",
        "\n",
        "  epoch_loss = 0\n",
        "  count = 0\n",
        "  for i, batch in enumerate(iterator):\n",
        "    #print(len(batch))\n",
        "    src = batch['en_tokens']\n",
        "    trg = batch['de_tokens']\n",
        "    #print(src.shape, trg.shape)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pred = model(src, trg)\n",
        "    output_dim = pred.shape[-1]\n",
        "    pred = pred[1:].view(-1, output_dim)\n",
        "    trg = trg.transpose(0, 1)\n",
        "    trg = trg[1:]\n",
        "    trg = trg.reshape(-1)\n",
        "    #print(pred.shape, trg.shape)\n",
        "    loss = lossfn(pred, trg)\n",
        "\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    count += 1\n",
        "\n",
        "  return epoch_loss/(count*128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fxSi86mviS1"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llTZYoF6l0Fy"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, lossfn):\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  count = 0\n",
        "  with torch.no_grad():\n",
        "    for i, batch in enumerate(iterator):\n",
        "      src = batch['en_tokens']\n",
        "      trg = batch['de_tokens']\n",
        "\n",
        "      pred = model(src, trg)\n",
        "      output_dim = pred.shape[-1]\n",
        "      pred = pred[1:].view(-1, output_dim)\n",
        "      trg = trg.transpose(0, 1)\n",
        "      trg = trg[1:]\n",
        "      trg = trg.reshape(-1)\n",
        "\n",
        "      loss = lossfn(pred, trg)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "      count += 1\n",
        "\n",
        "  return epoch_loss/(count*128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXxjGGKSnVoM"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGOfB74NvVYd",
        "outputId": "e2bdfedb-9304-4533-e99f-9a686a09935d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.029 | Train PPL:   1.029\n",
            "\t Val. Loss: 0.028 |  Val. PPL:   1.029\n",
            "\tTrain Loss: 0.026 | Train PPL:   1.026\n",
            "\t Val. Loss: 0.027 |  Val. PPL:   1.027\n",
            "\tTrain Loss: 0.023 | Train PPL:   1.023\n",
            "\t Val. Loss: 0.026 |  Val. PPL:   1.026\n",
            "\tTrain Loss: 0.020 | Train PPL:   1.021\n",
            "\t Val. Loss: 0.025 |  Val. PPL:   1.026\n",
            "\tTrain Loss: 0.018 | Train PPL:   1.019\n",
            "\t Val. Loss: 0.024 |  Val. PPL:   1.024\n",
            "\tTrain Loss: 0.017 | Train PPL:   1.017\n",
            "\t Val. Loss: 0.024 |  Val. PPL:   1.024\n",
            "\tTrain Loss: 0.015 | Train PPL:   1.015\n",
            "\t Val. Loss: 0.023 |  Val. PPL:   1.024\n",
            "\tTrain Loss: 0.014 | Train PPL:   1.014\n",
            "\t Val. Loss: 0.024 |  Val. PPL:   1.024\n",
            "\tTrain Loss: 0.013 | Train PPL:   1.013\n",
            "\t Val. Loss: 0.025 |  Val. PPL:   1.025\n",
            "\tTrain Loss: 0.012 | Train PPL:   1.012\n",
            "\t Val. Loss: 0.023 |  Val. PPL:   1.024\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, lossfn, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, lossfn)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    #epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "\n",
        "    #print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Done!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCi1daZUv-iK",
        "outputId": "e584508b-96f6-4367-ebb5-56211a77b4ea"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}